{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words353_filename = \"../Embeddings/wordsim_relatedness_goldstandard.txt\"\n",
    "cname = ['word1','word2','rating']\n",
    "df = pd.read_csv(words353_filename, sep='\\t', names = cname)\n",
    "# df = df[['word1','word2','rating']]\n",
    "\n",
    " \n",
    "column_values = df[[\"word1\", \"word2\"]].values.ravel()\n",
    "words_req =  pd.unique(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          rating       emb\nrating  1.000000 -0.099216\nemb    -0.099216  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>emb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rating</th>\n      <td>1.000000</td>\n      <td>-0.099216</td>\n    </tr>\n    <tr>\n      <th>emb</th>\n      <td>-0.099216</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data = np.load('../Embeddings/New Embeddings/WS_Rel_Emb_SG100.npy', allow_pickle=True).item()\n",
    "\n",
    "for k,v in data.items():\n",
    "    data.update({k.upper(): v})\n",
    "\n",
    "\n",
    "sim = []\n",
    "for index, row in df.iterrows():\n",
    "    w1 = row['word1'].upper()\n",
    "    # print(w1)\n",
    "    w2 = row['word2'].upper()\n",
    "    # print(w2)\n",
    "    sim.append(cosine_similarity(data[w1].reshape(1,-1), data[w2].reshape(1,-1)))\n",
    "    # print(cosine_similarity(data[w1].reshape(1,-1), data[w2].reshape(1,-1)))\n",
    "\n",
    "\n",
    "sim = np.array(sim).squeeze()\n",
    "df['emb'] = sim\n",
    "\n",
    "df.corr(method ='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SpearmanrResult(correlation=-0.08376093244494474, pvalue=0.1850441008824356)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "stats.spearmanr(df['emb'].values, df['rating'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitb225f4bd86994289a4055ad484dc0491"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}